<!DOCTYPE html>
<html>
    <head>
        <title>V Quidore coding and data portfolio</title>
        <meta charset="utf-8">
        <meta name="description" content="Coding and data projects">
        <meta name="keywords" content="V Quidore interactive multimedia games installations projects portfolio">
        <link rel="stylesheet" href="index-css/index-styles.css">
        
    </head>
    <header>
        <h1>
            V Quidore
        </h1>
        <nav>
            <a href="index.html">About</a> &nbsp;
            <a href="writing.html">Writing</a> &nbsp;
            <a href="audio-projects.html">Audio</a> &nbsp;
            <a href="code-stuff.html">Code + Data Stuff</a> &nbsp;
            <a href="interactive-multimedia-projects.html">Interactive + Multimedia</a> &nbsp;
            <a href="mission.html">Mission</a>
        </nav>
    </header>
    <body>
        <h1 style="font-size: 40px; padding-left: 20px;">
            Beep boop.
        </h1>
        <h1 style="margin-top: 60px; margin-bottom:30px;" onload="">
            New York Times Comedy Corpus (NYTCC)
        </h1>
        <h2 onload="">
            In 2023, I created the NYTCC using Python. The NYTCC is a 7.68-million-word corpus, 
            consisting of thousands of NYT articles about comedy written between 2003 and 2023. 
            I used this corpus to analyze changes in media infrastructures and discourse surrounding comedy over time. 
            If you would like to use the NYTCC, feel free to <a href="mailto:veronica.quidore@gmail.com">shoot me an email</a>!
        </h2>
        <h1 style="margin-top: 30px; margin-bottom:30px;">
            Conversation Vibrations
        </h1>
        <h2>
            My partner and I created Conversation Vibrations with for our term project in <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-29-06/">COSC 29.06/129: Digital Tangible User Interfaces</a>. It started with the question, 
            how can we blur the boundaries between our voices and visual art? 
            For this project, I coded the generative digital art in Processing, 
            and I used Autodesk to rapidly prototype custom parts for the Arduino motors, which powered the kinetic art board.
        </h2>
        <video controls>
            <source src="videos/Patil_Quidore_Conversation_Vibrations_video.webm" type="video/webm">
            Your browser does not support the video tag
        </video>
    </body>
    <footer>
    </footer>
</html>